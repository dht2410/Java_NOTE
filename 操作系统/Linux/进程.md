## Linux进程

这样说来，一个进程会有如下ID：

·PID：进程的唯一标识。对于多线程的进程而言，所有线程调用getpid函数会返回相同的值。

·PGID：进程组ID。每个进程都会有进程组ID，表示该进程所属的进程组。默认情况下新创建的进程会继承父进程的进程组ID。

·SID：会话ID。每个进程也都有会话ID。默认情况下，新创建的进程会继承父进程的会话ID。

PPID：父进程ID



进程组和会话是为了支持shell作业控制而引入的概念。

会话是一个或多个进程组的集合，囊括了登录用户的所有活动。

![image-20200927144414884](C:\Users\dht24\AppData\Roaming\Typora\typora-user-images\image-20200927144414884.png)

### fork()

Linux系统下，进程可以调用fork函数来创建新的进程。调用进程为父进程，被创建的进程为子进程。

与普通函数不同，fork函数会返回两次。fork函数的返回值就成了区分父子进程的关键。fork函数向子进程返回0，并将子进程的进程ID返给父进程。

**fork之后的子进程完全拷贝了父进程的地址空间，包括栈、堆、代码段等。**

#### 写时拷贝

Linux提供了execve系统调用，构建在该系统调用之上，glibc提供了exec系列函数。这个系列函数会丢弃现存的程序代码段，并构建新的数据段、栈及堆。调用fork之后，子进程几乎总是通过调用exec系列函数，来执行新的程序。

在这种背景下，fork时子进程完全拷贝父进程的数据段、栈和堆的做法是不明智的，因为接下来的exec系列函数会毫不留情地抛弃刚刚辛苦拷贝的内存。为了解决这个问题，Linux引入了**写时拷贝**（copy-on-write）的技术。

写时拷贝是指子进程的页表项指向与父进程相同的物理内存页，这样只拷贝父进程的页表项就可以了，当然要把这些页面标记成只读。如果父子进程都不修改内存的内容，大家便相安无事，共用一份物理内存页。但是一旦父
子进程中有任何一方尝试修改，就会引发缺页异常（page fault）。此时，内核会尝试为该页面创建一个新的物理页面，并将内容真正地复制到新的物理页面中，让父子进程真正地各自拥有自己的物理内存页，然后将页表中相应的表项标记为可写。

#### fork后父子进程和文件

父子进程共用了一套文件偏移量

为了解决子进程越权干涉父进程打开的文件，Linux引入了close on exec机制。设置了FD_CLOSEXEC标
志位的文件，在子进程调用exec家族函数时会将相应的文件关闭。

在内核的进程描述符task_struct结构体中，与打开文件相关的变量如下所示：

```c
struct test_struct{
    ...
    struct file_struct *files;
    ...
}
```

file_struct:

```c
struct files_struct {
    atomic_t count;
    struct fdtable __rcu *fdt;
    struct fdtable fdtab;
    spinlock_t file_lock ____cacheline_aligned_in_smp;
    int next_fd;
    struct embedded_fd_set close_on_exec_init;
    struct embedded_fd_set open_fds_init;
    struct file __rcu * fd_array[NR_OPEN_DEFAULT];
};
struct fdtable
{
    unsigned int max_fds;
    struct file __rcu **fd; /* current fd array */
    fd_set *close_on_exec;
    fd_set *open_fds;
    struct rcu_head rcu;
    struct fdtable *next;
};
struct embedded_fd_set {
    unsigned long fds_bits[1];
};
```

父子进程之间拷贝的是struct file的指针，而不是struct file的实例，父子进程的struct file类型指针，都指向同一个struct file实例。

父子进程是如何共享文件偏移量的?	那是因为父子进程的指针都指向了同一个struct file结构体。

### 地址空间

内核使用内存描述符来表示进程的地址空间，该描述符表示着进程所有地址空间的信息。内存描述符由 mm_struct 结构体表示。

```c
struct mm_struct {
    struct vm_area_struct *mmap;           /* 内存区域链表 */
    struct rb_root mm_rb;                  /* VMA 形成的红黑树 */
    ...
    struct list_head mmlist;               /* 所有 mm_struct 形成的链表 */
    ...
    unsigned long total_vm;                /* 全部页面数目 */
    unsigned long locked_vm;               /* 上锁的页面数据 */
    unsigned long pinned_vm;               /* Refcount permanently increased */
    unsigned long shared_vm;               /* 共享页面数目 Shared pages (files) */
    unsigned long exec_vm;                 /* 可执行页面数目 VM_EXEC & ~VM_WRITE */
    unsigned long stack_vm;                /* 栈区页面数目 VM_GROWSUP/DOWN */
    unsigned long def_flags;
    unsigned long start_code, end_code, start_data, end_data;    /* 代码段、数据段 起始地址和结束地址 */
    unsigned long start_brk, brk, start_stack;                   /* 栈区 的起始地址，堆区 起始地址和结束地址 */
    unsigned long arg_start, arg_end, env_start, env_end;        /* 命令行参数 和 环境变量的 起始地址和结束地址 */
    ...
    /* Architecture-specific MM context */
    mm_context_t context;                  /* 体系结构特殊数据 */

    /* Must use atomic bitops to access the bits */
    unsigned long flags;                   /* 状态标志位 */
    ...
    /* Coredumping and NUMA and HugePage 相关结构体 */
};
```

![img](https://img-blog.csdn.net/20160901214948512)

参考：

https://blog.csdn.net/yangkuanqaz85988/article/details/52403726

### 调度

调度器实体结构作为一个名为se的成员变量，嵌入在进程描述符task_struct中。

struct sched_entity se;

里面一个变量vruntime记录该进程运行的时间。CFS调度算法的核心：选择具有最小vruntime的进程。

CFS使用红黑树来组织可运行的进程队列，并利用其迅速找到最小vruntime值的进程。红黑树节点的key就是vruntime，因此就是最左侧叶子节点。

进程调度的入口是函数schedule()，它首先找到一个最高优先级的调度类。该调度类从自己的可运行队列中选出一个进程来。

睡眠和唤醒：**内核把进程标记成休眠（阻塞）状态，从可执行红黑树中移去，放入等待队列（一个进程列表，都等待同一个事件的发生），然后调用schedule函数选择和执行一个其他进程。唤醒时，进程被设置为可执行状态，然后从等待队列中移到可执行红黑树中。**

#### schedule函数触发和执行的时机

内核的调度操作分为**触发和执行**两个部分，触发时仅仅设置一下当前进程的TIF_NEED_RESCHED标志，执行的时候则是通过schedule()函数来完成进程的选择和切换。当前进程的thread_info->flags中TIF_NEED_RESCHED位表示需要调用schedule()函数进行调度。内核在两种情况下会设置该标志，一个是在时钟中断进行周期性的检查时，另一个是在被唤醒进程的优先级比正在运行的进程的优先级高时。

定时中断处理函数中会调用schedule_tick()用于**处理关于调度的周期性检查和处理**，其调用路径是和时钟处理有关的tick_periodic()->update_process_times()->scheduler_tick()或者tick_sched_handle()->update_process_times()->scheduler_tick()，主要用于更新就绪队列的时钟、CPU负载和当前任务的运行时间统计等。

```c
//linux-3.13/kernel/sched/core.c
void scheduler_tick(void)
{
  int cpu = smp_processor_id();         //获取当前cpu编号
  struct rq *rq = cpu_rq(cpu);         //取得对应cpu的rq（就绪队列）
  struct task_struct *curr = rq->curr;     //获取当前运行的任务
 
  sched_clock_tick();
 
  raw_spin_lock(&rq->lock);
  update_rq_clock(rq);             //更新队列时钟
  curr->sched_class->task_tick(rq, curr, 0);  //调用当前任务的调度类对应的函数
  update_cpu_load_active(rq);          //更新本处理器的负载
  raw_spin_unlock(&rq->lock);
 
  perf_event_task_tick();
 
#ifdef CONFIG_SMP
  rq->idle_balance = idle_cpu(cpu);
  trigger_load_balance(rq, cpu);        //必要时进行负载均衡
#endif
  rq_last_tick_reset(rq);
}
```

这行代码调用了当前任务的调度类的task_tick()函数，这个函数根据具体情况决定是否需要对当前任务设置TIF_NEED_RESCHED标志，如果需要则最终调用set_tsk_need_resched()设置该标志。需要注意的是，此处仅仅是设置标志而没有执行schedule()函数，在各种系统调用、中断的返回代码最后，才会根据这个标志来决定是否执行schedule()函数。

睡眠的任务被唤醒时：

当睡眠任务所等待的事件到达时，内核（例如驱动程序的中断处理函数）将会调用wake_up()唤醒相关的任务，并最终调用try_to_wake_up()。它完成三件事：

- 将任务重新添加到就绪队列
- 将运行标志设置为TASK_RUNNING
- 如果被唤醒的任务可以抢占当前运行任务则设置当前任务的TIF_NEED_RESCHED标志

设置了TIF_NEED_RESCHED标志之后，真正调用执行schedule()函数的时机只有两种

- **被动：**第一种是系统调用或者中断返回时，根据TIF_NEED_RESCHED标志决定是否调用schedule()函数（从效率方面考虑，趁着还在内核态把该处理的事情处理完毕）；
- **主动：**第二种情况是当前任务因为原因需要睡眠，进程睡眠后立即调用schedule()函数，在内核中这种情况也比较多，比如磁盘、网卡等设备驱动程序中。

### 上下文切换

schedule函数调用context_switch函数执行进程切换

1. 把虚拟内存从上一个进程映射切换到新进程
2. 从一个进程的处理器状态切换到新进程的处理器状态。包括保存恢复栈信息和寄存器信息，还有其他任何与体系结构相关的状态信息

### 守护进程

习惯上daemon进程的名字通常以d结尾，如sshd、rsyslogd等。

### 进程的终止

在不考虑线程的情况下，进程的退出有以下5种方式。
正常退出有3种：
·从main函数return返回
·调用exit
·调用_exit
异常退出有两种：
·调用abort
·接收到信号，由信号终止

![image-20200927173153744](C:\Users\dht24\AppData\Roaming\Typora\typora-user-images\image-20200927173153744.png)

### 僵尸进程

进程退出时会进行内核清理，基本就是释放进程所有的资源，这些资源包括**内存资源、文件资源、信号量资源、共享内存资源，或者引用计数减一，或者彻底释放。**不过，进程的退出其实并没有将所有的资源完全释放，仍保留了少量的资源，比如进程的PID依然被占用着，不可被系统分配。此时的进程不可运行，事实上也没有地址空间让其运行，进程进入僵尸状态。

僵尸进程依然保留的资源有进程控制块task_struct、内核栈等。这些资源不释放是为了提供一些重要的信息，比如进程为何退出，是收到信号退出还是正常退出，进程退出码是多少，进程一共消耗了多少系统CPU时间，多少用户CPU时间，收到了多少信号，发生了多少次上下文切换，最大内存驻留集是多少，产生多少缺页中断？等等。这些信息，就像墓志铭，总结了进程的一生。

进程退出后，会保留少量的资源，等待父进程前来收集这些信息。

只要父进程调用fork创建子进程，子进程退出后，父进程如果不调用wait或waitpid来获取子进程的退出信息，子进程就会沦为僵尸进程。

ps ax 可获得僵尸进程，状态为Z

清除僵尸进程有以下两种方法：
·父进程调用wait函数，为子进程“收尸”。
·父进程退出，init进程会为子进程“收尸”。

### wait

·子进程先退出，父进程后调用wait（）函数。直接执行，收尸
·父进程先调用wait（）函数，子进程后退出。父进程阻塞

wait（）函数等待的是任意一个子进程，任何一个子进程退出，都可以让其返回。

### exec

整个exec家族有6个函数，这些函数都是构建在execve系统调用之上的。该系统调用的作用是，将新程序加载到进程的地址空间，丢弃旧有的程序，进程的栈、数据段、堆栈等会被新程序替换。

一般来说，execve（）函数总是紧随fork函数之后。父进程调用fork之后，子进程执行execve函数，抛弃父进程的程序段，和父进程分道扬镳，从此天各一方，各走各路。

```c
//第一个参数是执行程序的路径
int execve(const char *filename, char *const argv[], char *const envp[]);
```

### system



### 进程等待

根据进程所属调度类别的不同，可运行状态的进程也会位于不同的队列上：如果是实时进程（属于实时调度类），则根据优先级的情况，落在相应的优先级的队列上；如果是普通进程（属于完全公平调度类），则根据虚拟运行
时间的大小，落在红黑树的相应位置上。

Linux存在两种睡眠的状态：**可中断的睡眠状态**（TASK_INTERRUPTIBLE）和**不可中断的睡眠状态**（TASK_UNINTERRUPTIBLE）。这两种睡眠状态是很类似的。两者的区别就在于能否响应收到的信号。

处于可中断的睡眠状态的进程，返回到可运行的状态有以下两种可能性：
·等待的事件发生了，继续运行的条件满足了。
·收到未被屏蔽的信号。

但是对于不可中断的睡眠状态，只有一种可能性能使其返回到可运行的状态，即等待的事件发生了，继续运行的条件满足了。

TASK_UNINTERRUPTIBLE状态存在的意义在于，内核中某些处理流程是不应该被打断的。**如read系统调用，等待缓存准备好时不应该被中断。**TASK_UNINTERRUPTIBLE是一种很危险的状态，因为进程进入该状态后，
刀枪不入，任何信号都无法打断它。**我们无法通过信号杀死一个处于不可中断的休眠状态的进程，SIGKILL信号也不行。**

内核提供了hung task检测机制，它会启动一个名为khungtaskd的内核线程来检测处于TASK_UNINTERRUPTIBLE状态的进程是否已经失控。

进程无论是处于可中断的睡眠状态还是不可中断的睡眠状态，有一个数据结构是绕不开的：**等待队列**（wait queue）。进程但凡需要休眠，必然是等待某种资源或等待某个事件，内核必须想办法将进程和它等待的资源（或事件）关联起来，当等待的资源可用或等待的事件已发生时，可以及时地唤醒相关的进程。内核采用的方法是等待队列。

当等待的事件发生时（或者说等待的条件满足时），这组进程会被唤醒，这类事件通常包括：中断（比如DISK I/O完成）、进程同步、休眠时间到时等。

![image-20200929114607277](C:\Users\dht24\AppData\Roaming\Typora\typora-user-images\image-20200929114607277.png)

- 等待队列元素的private成员变量指向了进程的进程描述符task_struct

- func为唤醒回调函数。在初始化等待队列元素的时候，需要注册回调函数func。当内核唤醒该进程时，就会执行等待队列元素中的回调函数。
  等待队列元素最常用的回调函数是default_wake_function，就像它的名字一样，是默认的唤醒回调函数。无论是DECLARE_WAITQUEUE还是init_waitqueue_entry，都将等待队列元素的func指向default_wake_function。而default_wake_function仅仅是大名鼎鼎的try_to_wake_up函数的简单封装，代码如下：

  ```c
  //try_to_wake_up是进程调度里非常重要的一个函数，它负责将睡眠的进程唤醒，并将醒来的进程放置到CPU的运行队列中，然后并设置进程的状态为TASK_RUNNING。
  int default_wake_function(wait_queue_t *curr, unsigned mode, int wake_flags,
  void *key)
  {
  	return try_to_wake_up(curr->private, mode, wake_flags);
  }
  ```

  

当内核需要等待某个条件满足而不得不休眠（或是可中断的睡眠，或是不可中断的睡眠）时，内核封装了一些宏来完成前面提到的流程。这些宏包括：

```c
//第一个参数指向的是等待队列头部，表示进程会睡眠在该等队列上。
//进程醒来时，condition需要得到满足，否则继续阻塞
wait_event(wq, condition)
wait_event_timeout(wq, condition, timeout)
wait_event_interruptible(wq, condition)
wait_event_interruptible_timeout(wq, condition, timeout)
```

在proc文件系统中，在/proc/PID/status中，记录了PID对应进程的状态信息。其中State项记录了该进程的瞬时状态。

### 进程的调度

目前Linux采用的是每个CPU都要有自己的运行队列，即per cpu run queue。每个CPU去自己的运行队列中选择进程，这样就降低了竞争。这种方案还有另外一个好处：缓存重利用。某个进程位于这个CPU的运行队列上，经过多次调度之后，内核趋于选择相同的CPU执行该进程。

Linux是可抢占式内核（Preemptive Kernel），从内核2.6版本开始，Linux不仅支持用户态抢占，也开始支持内核态抢占。**可抢占意味着正在执行的都是最高优先级进程。**

并不是所有的时机都允许发生内核抢占。以自旋锁为例，在内核可抢占的系统中，自旋锁持有期间不允许发生内核抢占，否则可能会导致其他CPU长期不能获得锁而死等。



